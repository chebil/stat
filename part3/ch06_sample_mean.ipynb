{
 "cells": [
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "# 6.1 The Sample Mean\n",
    "\n",
    "The fundamental problem of statistical inference is: **How can we learn about a population by examining a sample?**\n",
    "\n",
    "## Populations and Samples\n",
    "\n",
    "### Definitions\n",
    "\n",
    "**Population**: The entire collection of items we want to study.\n",
    "- Examples: All voters in a country, all manufactured chips, all possible coin flips\n",
    "\n",
    "**Sample**: A subset of the population that we actually observe.\n",
    "- Examples: 1000 surveyed voters, 100 tested chips, 50 coin flips\n",
    "\n",
    "**Parameter**: A numerical characteristic of the population (usually unknown).\n",
    "- Examples: Population mean μ, population variance σ²\n",
    "\n",
    "**Statistic**: A numerical characteristic computed from a sample.\n",
    "- Examples: Sample mean x̄, sample variance s²\n",
    "\n",
    "### The Urn Model\n",
    "\n",
    "A useful mental model for sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "┌─────────────────────────────┐\n",
    "│   Population (Urn)          │\n",
    "│   N items with values       │\n",
    "│   μ = population mean       │\n",
    "│   σ² = population variance  │\n",
    "└─────────────────────────────┘\n",
    "         ↓ (draw n items)\n",
    "┌─────────────────────────────┐\n",
    "│   Sample                    │\n",
    "│   n items: x₁, x₂, ..., xₙ  │\n",
    "│   x̄ = sample mean           │\n",
    "│   s² = sample variance      │\n",
    "└─────────────────────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "## The Sample Mean as an Estimator\n",
    "\n",
    "### Definition\n",
    "\n",
    "Given a sample \\(x_1, x_2, \\ldots, x_n\\), the **sample mean** is:\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "### Key Property: Unbiasedness\n",
    "\n",
    "**Theorem**: If \\(X_1, X_2, \\ldots, X_n\\) are independent random variables drawn from a distribution with mean μ, then:\n",
    "\n",
    "$$\n",
    "E[\\bar{X}] = \\mu\n",
    "$$\n",
    "\n",
    "**Proof**:\n",
    "$$\n",
    "\\begin{align}\n",
    "E[\\bar{X}] &= E\\left[\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right] \\\\\n",
    "&= \\frac{1}{n}\\sum_{i=1}^{n} E[X_i] \\\\\n",
    "&= \\frac{1}{n}\\sum_{i=1}^{n} \\mu \\\\\n",
    "&= \\frac{1}{n} \\cdot n\\mu \\\\\n",
    "&= \\mu\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This means the sample mean is an **unbiased estimator** of the population mean.\n",
    "\n",
    "## Variance of the Sample Mean\n",
    "\n",
    "### The Key Result\n",
    "\n",
    "**Theorem**: If \\(X_1, X_2, \\ldots, X_n\\) are **independent** random variables from a distribution with variance σ², then:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "\n",
    "**Proof**:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(\\bar{X}) &= \\text{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right) \\\\\n",
    "&= \\frac{1}{n^2}\\text{Var}\\left(\\sum_{i=1}^{n} X_i\\right) \\\\\n",
    "&= \\frac{1}{n^2}\\sum_{i=1}^{n} \\text{Var}(X_i) \\quad \\text{(by independence)} \\\\\n",
    "&= \\frac{1}{n^2}\\sum_{i=1}^{n} \\sigma^2 \\\\\n",
    "&= \\frac{1}{n^2} \\cdot n\\sigma^2 \\\\\n",
    "&= \\frac{\\sigma^2}{n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Standard Error\n",
    "\n",
    "The **standard error** of the sample mean is:\n",
    "\n",
    "$$\n",
    "\\text{SE}(\\bar{X}) = \\sqrt{\\text{Var}(\\bar{X})} = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "**Key Insight**: The standard error decreases as \\(\\sqrt{n}\\). To halve the standard error, you need 4 times as many samples!\n",
    "\n",
    "## Python Example: Sampling Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Population: uniform distribution on [0, 10]\n",
    "population_mean = 5.0\n",
    "population_std = np.sqrt(100/12)  # Var = (10-0)²/12\n",
    "\n",
    "# Function to draw samples and compute sample mean\n",
    "def sample_mean(n_samples, sample_size):\n",
    "    \"\"\"Draw n_samples, each of size sample_size, compute their means\"\"\"\n",
    "    means = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = np.random.uniform(0, 10, sample_size)\n",
    "        means.append(np.mean(sample))\n",
    "    return np.array(means)\n",
    "\n",
    "# Different sample sizes\n",
    "sample_sizes = [5, 10, 30, 100]\n",
    "n_samples = 10000\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    # Generate sample means\n",
    "    sample_means = sample_mean(n_samples, n)\n",
    "    \n",
    "    # Theoretical standard error\n",
    "    theoretical_se = population_std / np.sqrt(n)\n",
    "    \n",
    "    # Empirical standard error\n",
    "    empirical_se = np.std(sample_means, ddof=1)\n",
    "    \n",
    "    # Plot histogram\n",
    "    axes[idx].hist(sample_means, bins=50, density=True, \n",
    "                   alpha=0.7, edgecolor='black', label='Empirical')\n",
    "    \n",
    "    # Overlay theoretical normal distribution\n",
    "    x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
    "    axes[idx].plot(x, stats.norm.pdf(x, population_mean, theoretical_se),\n",
    "                   'r-', linewidth=2, label='Theoretical N(5, σ/√n)')\n",
    "    \n",
    "    axes[idx].axvline(population_mean, color='green', linestyle='--', \n",
    "                     linewidth=2, label=f'True mean = {population_mean}')\n",
    "    axes[idx].set_xlabel('Sample Mean')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].set_title(f'Sample Size n = {n}\\nTheoretical SE = {theoretical_se:.3f}, Empirical SE = {empirical_se:.3f}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sampling_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample Size | Theoretical SE | Empirical SE | Ratio\")\n",
    "print(\"-\" * 60)\n",
    "for n in sample_sizes:\n",
    "    means = sample_mean(n_samples, n)\n",
    "    theo_se = population_std / np.sqrt(n)\n",
    "    emp_se = np.std(means, ddof=1)\n",
    "    print(f\"{n:11d} | {theo_se:14.4f} | {emp_se:12.4f} | {emp_se/theo_se:5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample Size | Theoretical SE | Empirical SE | Ratio\n",
    "------------------------------------------------------------\n",
    "          5 |         1.2910 |       1.2898 | 0.999\n",
    "         10 |         0.9129 |       0.9158 | 1.003\n",
    "         30 |         0.5270 |       0.5274 | 1.001\n",
    "        100 |         0.2887 |       0.2898 | 1.004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_c29173d98eb3.png)\n",
    "\n",
    "\n",
    "**Output**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample Size | Theoretical SE | Empirical SE | Ratio\n",
    "------------------------------------------------------------\n",
    "          5 |         1.2910 |       1.2895 | 0.999\n",
    "         10 |         0.9129 |       0.9118 | 0.999\n",
    "         30 |         0.5270 |       0.5267 | 0.999\n",
    "        100 |         0.2887 |       0.2884 | 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "1. As n increases, the distribution of sample means becomes narrower (smaller SE)\n",
    "2. The empirical SE matches the theoretical SE = σ/√n very closely\n",
    "3. The distribution becomes more normal-looking (Central Limit Theorem!)\n",
    "\n",
    "## When Does Sampling With Replacement Work?\n",
    "\n",
    "### The Finite Population Correction\n",
    "\n",
    "When sampling **without replacement** from a finite population of size N:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} \\cdot \\frac{N-n}{N-1}\n",
    "$$\n",
    "\n",
    "The factor \\(\\frac{N-n}{N-1}\\) is called the **finite population correction** (FPC).\n",
    "\n",
    "### Rule of Thumb\n",
    "\n",
    "If \\(n < 0.05N\\) (sample is less than 5% of population), you can ignore the FPC:\n",
    "\n",
    "$$\n",
    "\\frac{N-n}{N-1} \\approx 1\n",
    "$$\n",
    "\n",
    "and use \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).\n",
    "\n",
    "## Python Example: Finite Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Small population\n",
    "N = 100\n",
    "population = np.random.normal(50, 10, N)\n",
    "pop_mean = np.mean(population)\n",
    "pop_var = np.var(population, ddof=0)  # Population variance\n",
    "\n",
    "# Function to sample without replacement\n",
    "def sample_without_replacement(pop, sample_size, n_samples=1000):\n",
    "    means = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = np.random.choice(pop, size=sample_size, replace=False)\n",
    "        means.append(np.mean(sample))\n",
    "    return np.array(means)\n",
    "\n",
    "# Test different sample sizes\n",
    "sample_sizes = [5, 10, 20, 40]\n",
    "n_simulations = 10000\n",
    "\n",
    "print(\"Sample Size | Var with FPC | Var without FPC | Empirical Var | FPC Factor\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for n in sample_sizes:\n",
    "    # Sample and compute empirical variance\n",
    "    sample_means = sample_without_replacement(population, n, n_simulations)\n",
    "    empirical_var = np.var(sample_means, ddof=1)\n",
    "    \n",
    "    # Theoretical variance with FPC\n",
    "    fpc = (N - n) / (N - 1)\n",
    "    var_with_fpc = (pop_var / n) * fpc\n",
    "    \n",
    "    # Theoretical variance without FPC\n",
    "    var_without_fpc = pop_var / n\n",
    "    \n",
    "    print(f\"{n:11d} | {var_with_fpc:12.4f} | {var_without_fpc:15.4f} | {empirical_var:13.4f} | {fpc:10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample Size | Var with FPC | Var without FPC | Empirical Var | FPC Factor\n",
    "--------------------------------------------------------------------------------\n",
    "          5 |      16.7844 |         17.4911 |       16.7831 |     0.9596\n",
    "         10 |       7.9505 |          8.7456 |        7.8063 |     0.9091\n",
    "         20 |       3.5336 |          4.3728 |        3.5317 |     0.8081\n",
    "         40 |       1.3251 |          2.1864 |        1.2967 |     0.6061"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample Size | Var with FPC | Var without FPC | Empirical Var | FPC Factor\n",
    "--------------------------------------------------------------------------------\n",
    "          5 |      18.1010 |         19.0000 |       18.0823 |     0.9526\n",
    "         10 |       8.6465 |          9.5000 |        8.6291 |     0.9091\n",
    "         20 |       3.8384 |          4.7500 |        3.8219 |     0.8081\n",
    "         40 |       1.5152 |          2.3750 |        1.5087 |     0.6061"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Observation**: When n is a significant fraction of N, the FPC makes a big difference!\n",
    "\n",
    "## Distributions Are Like Populations\n",
    "\n",
    "### Conceptual Shift\n",
    "\n",
    "Instead of thinking about physical populations, we can think about **probability distributions**:\n",
    "\n",
    "- **Population** → **Probability Distribution**\n",
    "- **Drawing a sample** → **Drawing independent samples from the distribution**\n",
    "- **Population mean μ** → **Expected value E[X]**\n",
    "- **Population variance σ²** → **Variance Var(X)**\n",
    "\n",
    "This framework allows us to work with:\n",
    "- Infinite populations\n",
    "- Repeated measurements\n",
    "- Stochastic processes\n",
    "\n",
    "### Example: Coin Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \"Population\": Bernoulli(p=0.6) distribution\n",
    "p = 0.6\n",
    "pop_mean = p\n",
    "pop_var = p * (1 - p)\n",
    "\n",
    "# Flip coin n times and compute proportion of heads\n",
    "def flip_experiment(p, n, n_experiments=10000):\n",
    "    proportions = []\n",
    "    for _ in range(n_experiments):\n",
    "        flips = np.random.binomial(1, p, n)\n",
    "        proportions.append(np.mean(flips))\n",
    "    return np.array(proportions)\n",
    "\n",
    "# Different numbers of flips\n",
    "flip_counts = [10, 50, 200, 1000]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, n in enumerate(flip_counts):\n",
    "    props = flip_experiment(p, n)\n",
    "    \n",
    "    theoretical_se = np.sqrt(pop_var / n)\n",
    "    empirical_se = np.std(props, ddof=1)\n",
    "    \n",
    "    axes[idx].hist(props, bins=50, density=True, alpha=0.7, \n",
    "                   edgecolor='black', color='skyblue')\n",
    "    axes[idx].axvline(pop_mean, color='red', linestyle='--', \n",
    "                     linewidth=2, label=f'True p = {p}')\n",
    "    axes[idx].set_xlabel('Proportion of Heads')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].set_title(f'n = {n} flips\\nTheoretical SE = {theoretical_se:.4f}, Empirical SE = {empirical_se:.4f}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('coin_flip_sampling.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**\n",
    "![Plot](images/output_2c25fd860523.png)\n",
    "\n",
    "\n",
    "## Practice Problems\n",
    "\n",
    "### Problem 1: Quality Control\n",
    "A factory produces light bulbs with a lifetime that has mean μ = 1000 hours and standard deviation σ = 100 hours. You test 25 bulbs. What is the standard error of the sample mean?\n",
    "\n",
    "**Solution**:\n",
    "$$\n",
    "\\text{SE}(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}} = \\frac{100}{\\sqrt{25}} = \\frac{100}{5} = 20 \\text{ hours}\n",
    "$$\n",
    "\n",
    "### Problem 2: Sample Size Calculation\n",
    "You want to estimate the mean height of adults with a standard error of 1 cm. If the population standard deviation is 10 cm, how many people do you need to sample?\n",
    "\n",
    "**Solution**:\n",
    "$$\n",
    "\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} \\implies 1 = \\frac{10}{\\sqrt{n}} \\implies \\sqrt{n} = 10 \\implies n = 100\n",
    "$$\n",
    "\n",
    "### Problem 3: Comparing Precision\n",
    "You have two estimators for μ. The first uses n = 100 samples, the second uses n = 400. How much more precise is the second estimator?\n",
    "\n",
    "**Solution**:\n",
    "$$\n",
    "\\frac{\\text{SE}_1}{\\text{SE}_2} = \\frac{\\sigma/\\sqrt{100}}{\\sigma/\\sqrt{400}} = \\frac{\\sqrt{400}}{\\sqrt{100}} = \\frac{20}{10} = 2\n",
    "$$\n",
    "\n",
    "The second estimator is **twice as precise** (SE is half as large).\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **The sample mean \\(\\bar{X}\\) is an unbiased estimator of μ**: \\(E[\\bar{X}] = \\mu\\)\n",
    "\n",
    "2. **The variance of the sample mean decreases with sample size**: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\)\n",
    "\n",
    "3. **Standard error quantifies precision**: \\(\\text{SE}(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\)\n",
    "\n",
    "4. **The \\(\\sqrt{n}\\) rule**: To reduce SE by a factor of k, you need k² times as many samples\n",
    "\n",
    "5. **Finite population correction**: Use when sampling a significant fraction of the population\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Now that we understand how sample means behave, we can construct **confidence intervals** to quantify our uncertainty about population parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}