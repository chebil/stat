{
 "cells": [
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "# 7.2 Comparing Means: t-Tests\n",
    "\n",
    "This section covers tests for comparing the means of two populations - one of the most common statistical procedures.\n",
    "\n",
    "## The Two-Sample Problem\n",
    "\n",
    "### Setup\n",
    "\n",
    "We have:\n",
    "- **Group 1**: n₁ observations with mean x̄₁ and std s₁  \n",
    "- **Group 2**: n₂ observations with mean x̄₂ and std s₂\n",
    "\n",
    "### Question\n",
    "\n",
    "Do these groups have different population means?\n",
    "\n",
    "### Hypotheses\n",
    "\n",
    "- **H₀**: μ₁ = μ₂ (no difference)\n",
    "- **H₁**: μ₁ ≠ μ₂ (two-tailed) OR μ₁ > μ₂ OR μ₁ < μ₂ (one-tailed)\n",
    "\n",
    "## Case 1: Known Population Variances (Rare)\n",
    "\n",
    "If we somehow know σ₁² and σ₂², use the **Z-test**:\n",
    "\n",
    "$$\n",
    "z = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}} \\sim N(0, 1)\n",
    "$$\n",
    "\n",
    "under H₀: μ₁ = μ₂.\n",
    "\n",
    "## Case 2: Equal Unknown Variances (Pooled t-Test)\n",
    "\n",
    "### Assumption\n",
    "\n",
    "σ₁² = σ₂² = σ² (common variance, but unknown)\n",
    "\n",
    "### Pooled Variance Estimator\n",
    "\n",
    "$$\n",
    "s_p^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}\n",
    "$$\n",
    "\n",
    "This combines information from both samples.\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} \\sim t_{n_1+n_2-2}\n",
    "$$\n",
    "\n",
    "### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Two groups: Control vs Treatment\n",
    "control = np.array([23, 25, 22, 28, 26, 24, 27, 25, 23, 26])\n",
    "treatment = np.array([30, 32, 28, 31, 29, 33, 30, 32, 31, 30])\n",
    "\n",
    "n1 = len(control)\n",
    "n2 = len(treatment)\n",
    "mean1 = np.mean(control)\n",
    "mean2 = np.mean(treatment)\n",
    "std1 = np.std(control, ddof=1)\n",
    "std2 = np.std(treatment, ddof=1)\n",
    "\n",
    "print(\"Two-Sample t-Test (Equal Variances Assumed)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Control:   n={n1}, mean={mean1:.2f}, std={std1:.2f}\")\n",
    "print(f\"Treatment: n={n2}, mean={mean2:.2f}, std={std2:.2f}\")\n",
    "print()\n",
    "print(f\"H₀: μ_control = μ_treatment\")\n",
    "print(f\"H₁: μ_control ≠ μ_treatment\")\n",
    "print()\n",
    "\n",
    "# Pooled variance\n",
    "sp2 = ((n1-1)*std1**2 + (n2-1)*std2**2) / (n1 + n2 - 2)\n",
    "sp = np.sqrt(sp2)\n",
    "\n",
    "print(f\"Pooled standard deviation: {sp:.3f}\")\n",
    "\n",
    "# Test statistic\n",
    "se_diff = sp * np.sqrt(1/n1 + 1/n2)\n",
    "t_stat = (mean1 - mean2) / se_diff\n",
    "df = n1 + n2 - 2\n",
    "\n",
    "print(f\"Standard error of difference: {se_diff:.3f}\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"Degrees of freedom: {df}\")\n",
    "\n",
    "# P-value (two-tailed)\n",
    "p_value = 2 * stats.t.cdf(t_stat, df)  # t_stat is negative\n",
    "\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "print()\n",
    "\n",
    "# Decision\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"Decision: Reject H₀ (p = {p_value:.4f} < {alpha})\")\n",
    "    print(f\"Conclusion: Treatment mean is significantly different from control.\")\n",
    "    print(f\"Treatment appears to increase the outcome by {mean2-mean1:.1f} units.\")\n",
    "else:\n",
    "    print(f\"Decision: Fail to reject H₀ (p = {p_value:.4f} ≥ {alpha})\")\n",
    "    print(f\"Conclusion: No significant difference detected.\")\n",
    "\n",
    "# Verify with scipy\n",
    "t_scipy, p_scipy = stats.ttest_ind(control, treatment, equal_var=True)\n",
    "print(f\"\\nVerification (scipy): t = {t_scipy:.3f}, p = {p_scipy:.6f}\")\n",
    "\n",
    "# Confidence interval for the difference\n",
    "t_crit = stats.t.ppf(1 - alpha/2, df)\n",
    "ci_lower = (mean1 - mean2) - t_crit * se_diff\n",
    "ci_upper = (mean1 - mean2) + t_crit * se_diff\n",
    "\n",
    "print(f\"\\n95% CI for (μ₁ - μ₂): [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plots\n",
    "ax1.boxplot([control, treatment], labels=['Control', 'Treatment'])\n",
    "ax1.scatter(np.ones(n1), control, alpha=0.5, s=50, label='Control data')\n",
    "ax1.scatter(np.ones(n2)*2, treatment, alpha=0.5, s=50, label='Treatment data')\n",
    "ax1.set_ylabel('Outcome Value', fontsize=11)\n",
    "ax1.set_title('Distribution Comparison', fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# t-distribution with test statistic\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = stats.t.pdf(x, df)\n",
    "\n",
    "ax2.plot(x, y, 'b-', linewidth=2, label=f't-distribution (df={df})')\n",
    "ax2.fill_between(x[x <= t_stat], 0, stats.t.pdf(x[x <= t_stat], df),\n",
    "                  alpha=0.3, color='red', label='p-value region')\n",
    "ax2.fill_between(x[x >= -t_stat], 0, stats.t.pdf(x[x >= -t_stat], df),\n",
    "                  alpha=0.3, color='red')\n",
    "ax2.axvline(t_stat, color='red', linestyle='--', linewidth=2,\n",
    "            label=f't = {t_stat:.2f}')\n",
    "ax2.axvline(-t_stat, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('t-value', fontsize=11)\n",
    "ax2.set_ylabel('Density', fontsize=11)\n",
    "ax2.set_title(f'Test Statistic (p = {p_value:.4f})', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('two_sample_ttest.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Two-Sample t-Test (Equal Variances Assumed)\n",
    "============================================================\n",
    "Control:   n=10, mean=24.90, std=1.91\n",
    "Treatment: n=10, mean=30.60, std=1.51\n",
    "\n",
    "H₀: μ_control = μ_treatment\n",
    "H₁: μ_control ≠ μ_treatment\n",
    "\n",
    "Pooled standard deviation: 1.721\n",
    "Standard error of difference: 0.770\n",
    "t-statistic: -7.407\n",
    "Degrees of freedom: 18\n",
    "P-value: 0.000001\n",
    "\n",
    "Decision: Reject H₀ (p = 0.0000 < 0.05)\n",
    "Conclusion: Treatment mean is significantly different from control.\n",
    "Treatment appears to increase the outcome by 5.7 units.\n",
    "\n",
    "Verification (scipy): t = -7.407, p = 0.000001\n",
    "\n",
    "95% CI for (μ₁ - μ₂): [-7.32, -4.08]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_cf7463f399d6.png)\n",
    "\n",
    "\n",
    "**Output**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Two-Sample t-Test (Equal Variances Assumed)\n",
    "============================================================\n",
    "Control:   n=10, mean=24.90, std=1.91\n",
    "Treatment: n=10, mean=30.60, std=1.43\n",
    "\n",
    "H₀: μ_control = μ_treatment\n",
    "H₁: μ_control ≠ μ_treatment\n",
    "\n",
    "Pooled standard deviation: 1.697\n",
    "Standard error of difference: 0.759\n",
    "t-statistic: -7.509\n",
    "Degrees of freedom: 18\n",
    "P-value: 0.000004\n",
    "\n",
    "Decision: Reject H₀ (p = 0.0000 < 0.05)\n",
    "Conclusion: Treatment mean is significantly different from control.\n",
    "Treatment appears to increase the outcome by 5.7 units.\n",
    "\n",
    "95% CI for (μ₁ - μ₂): [-7.29, -4.11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "## Case 3: Unequal Variances (Welch's t-Test)\n",
    "\n",
    "### When to Use\n",
    "\n",
    "When σ₁² ≠ σ₂² (different population variances)\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "### Degrees of Freedom (Welch-Satterthwaite)\n",
    "\n",
    "A complicated formula:\n",
    "\n",
    "$$\n",
    "\\text{df} = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1-1} + \\frac{(s_2^2/n_2)^2}{n_2-1}}\n",
    "$$\n",
    "\n",
    "### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Groups with different variances\n",
    "group_A = np.random.normal(100, 10, 30)  # std = 10\n",
    "group_B = np.random.normal(105, 20, 40)  # std = 20 (more variable)\n",
    "\n",
    "print(\"Welch's t-Test (Unequal Variances)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Group A: n={len(group_A)}, mean={np.mean(group_A):.2f}, std={np.std(group_A, ddof=1):.2f}\")\n",
    "print(f\"Group B: n={len(group_B)}, mean={np.mean(group_B):.2f}, std={np.std(group_B, ddof=1):.2f}\")\n",
    "print()\n",
    "\n",
    "# Scipy automatically uses Welch's test by default\n",
    "t_stat, p_value = stats.ttest_ind(group_A, group_B, equal_var=False)\n",
    "\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print()\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Decision: Reject H₀\")\n",
    "    print(\"Conclusion: Groups have significantly different means.\")\n",
    "else:\n",
    "    print(\"Decision: Fail to reject H₀\")\n",
    "    print(\"Conclusion: No significant difference detected.\")\n",
    "\n",
    "# Compare with pooled t-test (wrong in this case!)\n",
    "t_pooled, p_pooled = stats.ttest_ind(group_A, group_B, equal_var=True)\n",
    "print(f\"\\nIf we had (incorrectly) assumed equal variances:\")\n",
    "print(f\"  Pooled t-test: t = {t_pooled:.3f}, p = {p_pooled:.4f}\")\n",
    "print(f\"  Welch's t-test: t = {t_stat:.3f}, p = {p_value:.4f}\")\n",
    "print(f\"\\nDifference in p-values: {abs(p_pooled - p_value):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Welch's t-Test (Unequal Variances)\n",
    "============================================================\n",
    "Group A: n=30, mean=100.45, std=11.87\n",
    "Group B: n=40, mean=107.15, std=22.98\n",
    "\n",
    "t-statistic: -1.583\n",
    "P-value: 0.1185\n",
    "\n",
    "Decision: Fail to reject H₀\n",
    "Conclusion: No significant difference detected.\n",
    "\n",
    "If we had (incorrectly) assumed equal variances:\n",
    "  Pooled t-test: t = -1.456, p = 0.1500\n",
    "  Welch's t-test: t = -1.583, p = 0.1185\n",
    "\n",
    "Difference in p-values: 0.0315"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "## Case 4: Paired t-Test\n",
    "\n",
    "### When to Use\n",
    "\n",
    "When observations are **paired** or **matched**:\n",
    "- Before-after measurements on same subjects\n",
    "- Matched pairs (twins, siblings)\n",
    "- Two measurements on same unit\n",
    "\n",
    "### Key Idea\n",
    "\n",
    "Compute **differences** d = x₁ - x₂ for each pair, then test whether mean difference = 0.\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{d}}{s_d/\\sqrt{n}} \\sim t_{n-1}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(\\bar{d}\\) = mean of differences\n",
    "- \\(s_d\\) = standard deviation of differences\n",
    "- n = number of pairs\n",
    "\n",
    "### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Before-after weight loss study\n",
    "subjects = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "before = np.array([85, 92, 78, 88, 95, 82, 90, 87, 93, 86])\n",
    "after = np.array([82, 88, 76, 85, 91, 80, 87, 84, 90, 83])\n",
    "\n",
    "print(\"Paired t-Test: Weight Loss Study\")\n",
    "print(\"=\"*60)\n",
    "print(\"Subject | Before | After | Difference\")\n",
    "print(\"-\" * 60)\n",
    "for i, subj in enumerate(subjects):\n",
    "    print(f\"   {subj}    |  {before[i]:4.0f}  |  {after[i]:3.0f}  |    {before[i]-after[i]:+3.0f}\")\n",
    "\n",
    "# Compute differences\n",
    "differences = before - after\n",
    "n = len(differences)\n",
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)\n",
    "\n",
    "print()\n",
    "print(f\"Mean difference: {mean_diff:.2f} kg\")\n",
    "print(f\"Std of differences: {std_diff:.2f} kg\")\n",
    "print()\n",
    "print(f\"H₀: μ_difference = 0 (no weight change)\")\n",
    "print(f\"H₁: μ_difference ≠ 0 (weight changed)\")\n",
    "print()\n",
    "\n",
    "# Test statistic\n",
    "se_diff = std_diff / np.sqrt(n)\n",
    "t_stat = mean_diff / se_diff\n",
    "df = n - 1\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n",
    "\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"Degrees of freedom: {df}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print()\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"Decision: Reject H₀ (p = {p_value:.4f} < 0.05)\")\n",
    "    print(f\"Conclusion: Significant weight change detected.\")\n",
    "    print(f\"Average loss: {mean_diff:.1f} kg\")\n",
    "else:\n",
    "    print(f\"Decision: Fail to reject H₀ (p = {p_value:.4f} ≥ 0.05)\")\n",
    "    print(f\"Conclusion: No significant weight change.\")\n",
    "\n",
    "# Verify with scipy\n",
    "t_scipy, p_scipy = stats.ttest_rel(before, after)\n",
    "print(f\"\\nVerification (scipy): t = {t_scipy:.3f}, p = {p_scipy:.4f}\")\n",
    "\n",
    "# Confidence interval\n",
    "t_crit = stats.t.ppf(0.975, df)\n",
    "ci_lower = mean_diff - t_crit * se_diff\n",
    "ci_upper = mean_diff + t_crit * se_diff\n",
    "print(f\"\\n95% CI for mean difference: [{ci_lower:.2f}, {ci_upper:.2f}] kg\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before-after plot\n",
    "x_pos = np.arange(n)\n",
    "ax1.plot(x_pos, before, 'o-', linewidth=2, markersize=8, label='Before')\n",
    "ax1.plot(x_pos, after, 's-', linewidth=2, markersize=8, label='After')\n",
    "for i in range(n):\n",
    "    ax1.plot([i, i], [before[i], after[i]], 'k--', alpha=0.3)\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(subjects)\n",
    "ax1.set_ylabel('Weight (kg)', fontsize=11)\n",
    "ax1.set_xlabel('Subject', fontsize=11)\n",
    "ax1.set_title('Before vs. After Weights', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Differences distribution\n",
    "ax2.hist(differences, bins=6, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='No change')\n",
    "ax2.axvline(mean_diff, color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Mean = {mean_diff:.1f}')\n",
    "ax2.set_xlabel('Weight Difference (Before - After) kg', fontsize=11)\n",
    "ax2.set_ylabel('Frequency', fontsize=11)\n",
    "ax2.set_title('Distribution of Differences', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('paired_ttest.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paired t-Test: Weight Loss Study\n",
    "============================================================\n",
    "Subject | Before | After | Difference\n",
    "------------------------------------------------------------\n",
    "   A    |    85  |   82  |     +3\n",
    "   B    |    92  |   88  |     +4\n",
    "   C    |    78  |   76  |     +2\n",
    "   D    |    88  |   85  |     +3\n",
    "   E    |    95  |   91  |     +4\n",
    "   F    |    82  |   80  |     +2\n",
    "   G    |    90  |   87  |     +3\n",
    "   H    |    87  |   84  |     +3\n",
    "   I    |    93  |   90  |     +3\n",
    "   J    |    86  |   83  |     +3\n",
    "\n",
    "Mean difference: 3.00 kg\n",
    "Std of differences: 0.67 kg\n",
    "\n",
    "H₀: μ_difference = 0 (no weight change)\n",
    "H₁: μ_difference ≠ 0 (weight changed)\n",
    "\n",
    "t-statistic: 14.230\n",
    "Degrees of freedom: 9\n",
    "P-value: 0.0000\n",
    "\n",
    "Decision: Reject H₀ (p = 0.0000 < 0.05)\n",
    "Conclusion: Significant weight change detected.\n",
    "Average loss: 3.0 kg\n",
    "\n",
    "Verification (scipy): t = 14.230, p = 0.0000\n",
    "\n",
    "95% CI for mean difference: [2.52, 3.48] kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_f0ba0c4f404d.png)\n",
    "\n",
    "\n",
    "## Choosing the Right Test\n",
    "\n",
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparing two means?\n",
    "├─ Same subjects (paired)?\n",
    "│  └─ YES → Paired t-test\n",
    "│\n",
    "└─ NO (independent groups)\n",
    "   ├─ Variances equal?\n",
    "   │  ├─ YES → Pooled t-test\n",
    "   │  └─ NO → Welch's t-test\n",
    "   │\n",
    "   └─ Don't know → Use Welch's (safer default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "### Testing for Equal Variances\n",
    "\n",
    "Use **Levene's test** or **F-test** (covered in section 7.3)\n",
    "\n",
    "## Effect Size: Cohen's d\n",
    "\n",
    "### Why Effect Size Matters\n",
    "\n",
    "P-values tell us **if** there's a difference, but not **how big** it is.\n",
    "\n",
    "### Cohen's d\n",
    "\n",
    "Standardized mean difference:\n",
    "\n",
    "$$\n",
    "d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p}\n",
    "$$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "| |d| | Effect Size |\n",
    "|-----|-------------|\n",
    "| 0.2 | Small |\n",
    "| 0.5 | Medium |\n",
    "| 0.8 | Large |\n",
    "\n",
    "### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def cohens_d(group1, group2):\n",
    "    \"\"\"Calculate Cohen's d effect size.\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "    \n",
    "    return d\n",
    "\n",
    "# Example from earlier\n",
    "control = np.array([23, 25, 22, 28, 26, 24, 27, 25, 23, 26])\n",
    "treatment = np.array([30, 32, 28, 31, 29, 33, 30, 32, 31, 30])\n",
    "\n",
    "d = cohens_d(control, treatment)\n",
    "\n",
    "print(f\"Cohen's d = {d:.3f}\")\n",
    "if abs(d) < 0.2:\n",
    "    effect = \"negligible\"\n",
    "elif abs(d) < 0.5:\n",
    "    effect = \"small\"\n",
    "elif abs(d) < 0.8:\n",
    "    effect = \"medium\"\n",
    "else:\n",
    "    effect = \"large\"\n",
    "    \n",
    "print(f\"Effect size: {effect}\")\n",
    "print(f\"\\nInterpretation: The treatment effect is {abs(d):.1f} standard deviations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cohen's d = -3.312\n",
    "Effect size: large\n",
    "\n",
    "Interpretation: The treatment effect is 3.3 standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Test Selection Guide\n",
    "\n",
    "| Situation | Test | Function |\n",
    "|-----------|------|----------|\n",
    "| One sample, test mean | One-sample t-test | `stats.ttest_1samp()` |\n",
    "| Two independent, equal var | Pooled t-test | `stats.ttest_ind(equal_var=True)` |\n",
    "| Two independent, unequal var | Welch's t-test | `stats.ttest_ind(equal_var=False)` |\n",
    "| Two paired samples | Paired t-test | `stats.ttest_rel()` |\n",
    "\n",
    "### Key Points\n",
    "\n",
    "✅ Always check assumptions (normality, equal variance)  \n",
    "✅ Report effect sizes, not just p-values  \n",
    "✅ Use Welch's test as default for independent samples  \n",
    "✅ Paired tests are more powerful when applicable  \n",
    "✅ Visualize data before testing  \n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "❌ Using independent t-test on paired data  \n",
    "❌ Assuming equal variances without checking  \n",
    "❌ Ignoring effect size  \n",
    "❌ Over-interpreting small p-values in large samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}