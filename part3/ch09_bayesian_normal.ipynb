{
 "cells": [
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "# 9.4 Bayesian Inference for Normal Distribution\n",
    "\n",
    "## Normal Distribution with Unknown Mean\n",
    "\n",
    "### Setup\n",
    "\n",
    "**Data**: \\(x_1, \\ldots, x_n \\sim N(\\mu, \\sigma^2)\\) where \\(\\sigma^2\\) is **known**\n",
    "\n",
    "**Goal**: Infer \\(\\mu\\)\n",
    "\n",
    "### Prior\n",
    "\n",
    "**Conjugate prior**: \\(\\mu \\sim N(\\mu_0, \\sigma_0^2)\\)\n",
    "\n",
    "This represents our belief about \\(\\mu\\) before seeing data.\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "For a single observation:\n",
    "$$\n",
    "p(x \\mid \\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "For n observations:\n",
    "$$\n",
    "p(x_1, \\ldots, x_n \\mid \\mu) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i - \\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "### Posterior Derivation\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "$$\n",
    "p(\\mu \\mid x_1, \\ldots, x_n) \\propto p(x_1, \\ldots, x_n \\mid \\mu) \\cdot p(\\mu)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i - \\mu)^2\\right) \\cdot \\exp\\left(-\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2}\\right)\n",
    "$$\n",
    "\n",
    "Completing the square (algebra omitted), we get:\n",
    "\n",
    "**Posterior**: \\(\\mu \\mid x_1, \\ldots, x_n \\sim N(\\mu_n, \\sigma_n^2)\\)\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\sigma_n^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_n = \\sigma_n^2 \\left(\\frac{\\mu_0}{\\sigma_0^2} + \\frac{n\\bar{x}}{\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "### Precision Form (Cleaner)\n",
    "\n",
    "Define **precision** \\(\\tau = 1/\\sigma^2\\):\n",
    "\n",
    "$$\n",
    "\\tau_n = \\tau_0 + n\\tau \\quad \\text{(precisions add!)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_n = \\frac{\\tau_0 \\mu_0 + n\\tau\\bar{x}}{\\tau_n}\n",
    "$$\n",
    "\n",
    "The posterior mean is a **precision-weighted average** of prior mean and sample mean.\n",
    "\n",
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# True parameters (unknown to the model)\n",
    "true_mu = 10\n",
    "true_sigma = 2\n",
    "\n",
    "# Generate data\n",
    "n_samples = [1, 5, 10, 20, 50]\n",
    "all_data = np.random.normal(true_mu, true_sigma, max(n_samples))\n",
    "\n",
    "# Prior: N(mu_0=5, sigma_0=5)\n",
    "mu_0 = 5\n",
    "sigma_0 = 5\n",
    "\n",
    "print(\"Bayesian Inference for Normal Mean\")\n",
    "print(\"=\"*70)\n",
    "print(f\"True μ: {true_mu}, True σ: {true_sigma}\")\n",
    "print(f\"Prior: N({mu_0}, {sigma_0}²)\")\n",
    "print(f\"Known σ: {true_sigma}\")\n",
    "print()\n",
    "\n",
    "# Create subplots for different sample sizes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "mu_values = np.linspace(-5, 20, 1000)\n",
    "\n",
    "# Prior distribution\n",
    "prior = stats.norm.pdf(mu_values, mu_0, sigma_0)\n",
    "axes[0].plot(mu_values, prior, 'b-', linewidth=2)\n",
    "axes[0].axvline(mu_0, color='blue', linestyle='--', linewidth=2,\n",
    "               label=f'Prior mean = {mu_0}')\n",
    "axes[0].axvline(true_mu, color='green', linestyle='--', linewidth=2,\n",
    "               label=f'True μ = {true_mu}')\n",
    "axes[0].set_xlabel('μ', fontsize=11)\n",
    "axes[0].set_ylabel('Density', fontsize=11)\n",
    "axes[0].set_title('Prior Distribution', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Posteriors for increasing sample sizes\n",
    "for idx, n in enumerate(n_samples):\n",
    "    data = all_data[:n]\n",
    "    xbar = np.mean(data)\n",
    "    \n",
    "    # Posterior parameters\n",
    "    sigma_n_sq = 1 / (1/sigma_0**2 + n/true_sigma**2)\n",
    "    sigma_n = np.sqrt(sigma_n_sq)\n",
    "    mu_n = sigma_n_sq * (mu_0/sigma_0**2 + n*xbar/true_sigma**2)\n",
    "    \n",
    "    # Posterior distribution\n",
    "    posterior = stats.norm.pdf(mu_values, mu_n, sigma_n)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx + 1]\n",
    "    ax.plot(mu_values, prior, 'b--', linewidth=1, alpha=0.5, label='Prior')\n",
    "    ax.plot(mu_values, posterior, 'r-', linewidth=2, label='Posterior')\n",
    "    ax.axvline(mu_n, color='red', linestyle='--', linewidth=2,\n",
    "              label=f'Post. mean = {mu_n:.2f}')\n",
    "    ax.axvline(xbar, color='orange', linestyle=':', linewidth=2,\n",
    "              label=f'Sample mean = {xbar:.2f}')\n",
    "    ax.axvline(true_mu, color='green', linestyle='--', linewidth=2,\n",
    "              label=f'True μ = {true_mu}')\n",
    "    \n",
    "    # 95% Credible interval\n",
    "    ci_lower = stats.norm.ppf(0.025, mu_n, sigma_n)\n",
    "    ci_upper = stats.norm.ppf(0.975, mu_n, sigma_n)\n",
    "    ax.fill_between(mu_values[(mu_values >= ci_lower) & (mu_values <= ci_upper)],\n",
    "                     0,\n",
    "                     posterior[(mu_values >= ci_lower) & (mu_values <= ci_upper)],\n",
    "                     alpha=0.3, color='red')\n",
    "    \n",
    "    ax.set_xlabel('μ', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title(f'After n={n} observations', fontsize=12)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    print(f\"n={n:2d}: x̄={xbar:6.2f}, Posterior N({mu_n:.2f}, {sigma_n:.2f}²), 95% CI=[{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bayesian_normal_mean.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian Inference for Normal Mean\n",
    "======================================================================\n",
    "True μ: 10, True σ: 2\n",
    "Prior: N(5, 5²)\n",
    "Known σ: 2\n",
    "\n",
    "n= 1: x̄= 10.99, Posterior N(10.17, 1.86²), 95% CI=[6.53, 13.81]\n",
    "n= 5: x̄= 10.92, Posterior N(10.73, 0.88²), 95% CI=[9.01, 12.46]\n",
    "n=10: x̄= 10.90, Posterior N(10.80, 0.63²), 95% CI=[9.57, 12.03]\n",
    "n=20: x̄=  9.66, Posterior N(9.62, 0.45²), 95% CI=[8.75, 10.49]\n",
    "n=50: x̄=  9.55, Posterior N(9.53, 0.28²), 95% CI=[8.98, 10.09]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_e7182d5bf2a3.png)\n",
    "\n",
    "\n",
    "## Normal Distribution with Unknown Variance\n",
    "\n",
    "### Setup\n",
    "\n",
    "**Data**: \\(x_1, \\ldots, x_n \\sim N(\\mu, \\sigma^2)\\) where \\(\\mu\\) is **known**\n",
    "\n",
    "**Goal**: Infer \\(\\sigma^2\\)\n",
    "\n",
    "### Prior\n",
    "\n",
    "**Conjugate prior**: \\(\\sigma^2 \\sim \\text{Inverse-Gamma}(\\alpha, \\beta)\\)\n",
    "\n",
    "PDF:\n",
    "$$\n",
    "p(\\sigma^2) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}(\\sigma^2)^{-(\\alpha+1)}\\exp\\left(-\\frac{\\beta}{\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "$$\n",
    "p(x_1, \\ldots, x_n \\mid \\sigma^2) \\propto (\\sigma^2)^{-n/2}\\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "### Posterior\n",
    "\n",
    "$$\n",
    "\\sigma^2 \\mid x_1, \\ldots, x_n \\sim \\text{Inverse-Gamma}\\left(\\alpha + \\frac{n}{2}, \\beta + \\frac{1}{2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# True parameters\n",
    "true_mu = 0  # Known\n",
    "true_sigma2 = 4  # Unknown\n",
    "\n",
    "# Generate data\n",
    "n = 30\n",
    "data = np.random.normal(true_mu, np.sqrt(true_sigma2), n)\n",
    "\n",
    "# Prior: Inverse-Gamma(3, 2)\n",
    "alpha_prior = 3\n",
    "beta_prior = 2\n",
    "\n",
    "print(\"Bayesian Inference for Normal Variance\")\n",
    "print(\"=\"*70)\n",
    "print(f\"True σ²: {true_sigma2}\")\n",
    "print(f\"Known μ: {true_mu}\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print()\n",
    "\n",
    "# Posterior parameters\n",
    "ss = np.sum((data - true_mu)**2)  # Sum of squares\n",
    "alpha_post = alpha_prior + n/2\n",
    "beta_post = beta_prior + ss/2\n",
    "\n",
    "print(f\"Prior: Inverse-Gamma({alpha_prior}, {beta_prior})\")\n",
    "print(f\"  Prior mean: {beta_prior/(alpha_prior-1):.2f}\")\n",
    "print()\n",
    "print(f\"Posterior: Inverse-Gamma({alpha_post:.1f}, {beta_post:.2f})\")\n",
    "print(f\"  Posterior mean: {beta_post/(alpha_post-1):.2f}\")\n",
    "\n",
    "# Visualization\n",
    "sigma2_values = np.linspace(0.1, 15, 1000)\n",
    "\n",
    "# Prior (using scipy.stats.invgamma)\n",
    "prior = stats.invgamma.pdf(sigma2_values, alpha_prior, scale=beta_prior)\n",
    "\n",
    "# Posterior\n",
    "posterior = stats.invgamma.pdf(sigma2_values, alpha_post, scale=beta_post)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prior and posterior\n",
    "ax1.plot(sigma2_values, prior, 'b--', linewidth=2, label='Prior', alpha=0.7)\n",
    "ax1.plot(sigma2_values, posterior, 'r-', linewidth=2, label='Posterior')\n",
    "ax1.axvline(true_sigma2, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'True σ² = {true_sigma2}')\n",
    "ax1.axvline(beta_post/(alpha_post-1), color='red', linestyle=':', linewidth=2,\n",
    "           label=f'Post. mean = {beta_post/(alpha_post-1):.2f}')\n",
    "ax1.set_xlabel('σ²', fontsize=12)\n",
    "ax1.set_ylabel('Density', fontsize=12)\n",
    "ax1.set_title('Prior and Posterior for Variance', fontsize=13)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.set_xlim(0, 12)\n",
    "\n",
    "# Credible interval\n",
    "ci_lower = stats.invgamma.ppf(0.025, alpha_post, scale=beta_post)\n",
    "ci_upper = stats.invgamma.ppf(0.975, alpha_post, scale=beta_post)\n",
    "\n",
    "ax2.fill_between(sigma2_values, 0, posterior, alpha=0.3, color='red')\n",
    "ax2.fill_between(sigma2_values[(sigma2_values >= ci_lower) & (sigma2_values <= ci_upper)],\n",
    "                  0,\n",
    "                  posterior[(sigma2_values >= ci_lower) & (sigma2_values <= ci_upper)],\n",
    "                  alpha=0.5, color='darkred',\n",
    "                  label=f'95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]')\n",
    "ax2.plot(sigma2_values, posterior, 'r-', linewidth=2)\n",
    "ax2.axvline(true_sigma2, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'True σ² = {true_sigma2}')\n",
    "ax2.set_xlabel('σ²', fontsize=12)\n",
    "ax2.set_ylabel('Posterior Density', fontsize=12)\n",
    "ax2.set_title('Posterior Distribution', fontsize=13)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_xlim(0, 12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bayesian_normal_variance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n95% Credible Interval for σ²: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "print(f\"True σ² = {true_sigma2} is {'inside' if ci_lower <= true_sigma2 <= ci_upper else 'outside'} the interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian Inference for Normal Variance\n",
    "======================================================================\n",
    "True σ²: 4\n",
    "Known μ: 0\n",
    "Sample size: 30\n",
    "\n",
    "Prior: Inverse-Gamma(3, 2)\n",
    "  Prior mean: 1.00\n",
    "\n",
    "Posterior: Inverse-Gamma(18.0, 51.10)\n",
    "  Posterior mean: 3.01\n",
    "\n",
    "95% Credible Interval for σ²: [1.878, 4.790]\n",
    "True σ² = 4 is inside the interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_ee0fdd2ef278.png)\n",
    "\n",
    "\n",
    "## Normal with Both Parameters Unknown\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "When **both** \\(\\mu\\) and \\(\\sigma^2\\) are unknown, we need a **joint prior**.\n",
    "\n",
    "### Normal-Gamma Conjugate Prior\n",
    "\n",
    "**Joint prior**: \n",
    "$$\n",
    "p(\\mu, \\sigma^2) = p(\\mu \\mid \\sigma^2) \\cdot p(\\sigma^2)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(\\sigma^2 \\sim \\text{Inverse-Gamma}(\\alpha, \\beta)\\)\n",
    "- \\(\\mu \\mid \\sigma^2 \\sim N\\left(\\mu_0, \\frac{\\sigma^2}{\\kappa_0}\\right)\\)\n",
    "\n",
    "This is called the **Normal-Gamma** (or **Normal-Inverse-Gamma**) distribution.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- \\(\\mu_0\\): prior guess for mean\n",
    "- \\(\\kappa_0\\): \"pseudo-observations\" for mean (confidence in \\(\\mu_0\\))\n",
    "- \\(\\alpha\\): shape for variance\n",
    "- \\(\\beta\\): scale for variance\n",
    "\n",
    "### Posterior\n",
    "\n",
    "Given data \\(x_1, \\ldots, x_n\\):\n",
    "\n",
    "$$\n",
    "\\mu, \\sigma^2 \\mid x_1, \\ldots, x_n \\sim \\text{Normal-Gamma}(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\kappa_n = \\kappa_0 + n\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_n = \\frac{\\kappa_0 \\mu_0 + n\\bar{x}}{\\kappa_n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha_n = \\alpha + \\frac{n}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_n = \\beta + \\frac{1}{2}\\sum_{i=1}^{n}(x_i - \\bar{x})^2 + \\frac{\\kappa_0 n(\\bar{x} - \\mu_0)^2}{2\\kappa_n}\n",
    "$$\n",
    "\n",
    "### Marginal Posteriors\n",
    "\n",
    "**For \\(\\sigma^2\\)**:\n",
    "$$\n",
    "\\sigma^2 \\mid x_1, \\ldots, x_n \\sim \\text{Inverse-Gamma}(\\alpha_n, \\beta_n)\n",
    "$$\n",
    "\n",
    "**For \\(\\mu\\)** (marginalized over \\(\\sigma^2\\)):\n",
    "$$\n",
    "\\mu \\mid x_1, \\ldots, x_n \\sim t_{2\\alpha_n}\\left(\\mu_n, \\frac{\\beta_n}{\\alpha_n \\kappa_n}\\right)\n",
    "$$\n",
    "\n",
    "This is a **Student's t-distribution** with \\(2\\alpha_n\\) degrees of freedom!\n",
    "\n",
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# True parameters (both unknown)\n",
    "true_mu = 10\n",
    "true_sigma2 = 4\n",
    "\n",
    "# Generate data\n",
    "n = 20\n",
    "data = np.random.normal(true_mu, np.sqrt(true_sigma2), n)\n",
    "xbar = np.mean(data)\n",
    "ss = np.sum((data - xbar)**2)\n",
    "\n",
    "print(\"Bayesian Inference for Normal (both parameters unknown)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"True parameters: μ = {true_mu}, σ² = {true_sigma2}\")\n",
    "print(f\"Data: n = {n}, x̄ = {xbar:.2f}\")\n",
    "print()\n",
    "\n",
    "# Prior hyperparameters (weakly informative)\n",
    "mu_0 = 8      # Prior mean\n",
    "kappa_0 = 1   # Prior \"sample size\" for mean\n",
    "alpha = 2     # Prior shape for variance\n",
    "beta = 2      # Prior scale for variance\n",
    "\n",
    "print(f\"Prior: Normal-Gamma({mu_0}, {kappa_0}, {alpha}, {beta})\")\n",
    "print()\n",
    "\n",
    "# Posterior hyperparameters\n",
    "kappa_n = kappa_0 + n\n",
    "mu_n = (kappa_0 * mu_0 + n * xbar) / kappa_n\n",
    "alpha_n = alpha + n/2\n",
    "beta_n = beta + 0.5*ss + (kappa_0*n*(xbar - mu_0)**2)/(2*kappa_n)\n",
    "\n",
    "print(f\"Posterior: Normal-Gamma({mu_n:.2f}, {kappa_n}, {alpha_n:.1f}, {beta_n:.2f})\")\n",
    "print()\n",
    "print(f\"Posterior mean of μ: {mu_n:.2f}\")\n",
    "print(f\"Posterior mean of σ²: {beta_n/(alpha_n-1):.2f}\")\n",
    "\n",
    "# Marginal posterior for mu (Student's t)\n",
    "df_mu = 2 * alpha_n\n",
    "scale_mu = np.sqrt(beta_n / (alpha_n * kappa_n))\n",
    "\n",
    "ci_mu_lower = stats.t.ppf(0.025, df_mu, loc=mu_n, scale=scale_mu)\n",
    "ci_mu_upper = stats.t.ppf(0.975, df_mu, loc=mu_n, scale=scale_mu)\n",
    "\n",
    "print(f\"\\nMarginal posterior for μ: t_{{{df_mu:.0f}}}({mu_n:.2f}, {scale_mu:.2f}²)\")\n",
    "print(f\"95% Credible Interval for μ: [{ci_mu_lower:.2f}, {ci_mu_upper:.2f}]\")\n",
    "\n",
    "# Marginal posterior for sigma^2\n",
    "ci_sigma2_lower = stats.invgamma.ppf(0.025, alpha_n, scale=beta_n)\n",
    "ci_sigma2_upper = stats.invgamma.ppf(0.975, alpha_n, scale=beta_n)\n",
    "\n",
    "print(f\"\\nMarginal posterior for σ²: Inverse-Gamma({alpha_n:.1f}, {beta_n:.2f})\")\n",
    "print(f\"95% Credible Interval for σ²: [{ci_sigma2_lower:.2f}, {ci_sigma2_upper:.2f}]\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Marginal posterior for mu\n",
    "mu_values = np.linspace(7, 13, 1000)\n",
    "posterior_mu = stats.t.pdf(mu_values, df_mu, loc=mu_n, scale=scale_mu)\n",
    "\n",
    "ax1.fill_between(mu_values, 0, posterior_mu, alpha=0.3, color='blue')\n",
    "ax1.fill_between(mu_values[(mu_values >= ci_mu_lower) & (mu_values <= ci_mu_upper)],\n",
    "                  0,\n",
    "                  posterior_mu[(mu_values >= ci_mu_lower) & (mu_values <= ci_mu_upper)],\n",
    "                  alpha=0.5, color='darkblue',\n",
    "                  label=f'95% CI: [{ci_mu_lower:.2f}, {ci_mu_upper:.2f}]')\n",
    "ax1.plot(mu_values, posterior_mu, 'b-', linewidth=2)\n",
    "ax1.axvline(mu_n, color='blue', linestyle='--', linewidth=2,\n",
    "           label=f'Post. mean = {mu_n:.2f}')\n",
    "ax1.axvline(true_mu, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'True μ = {true_mu}')\n",
    "ax1.set_xlabel('μ', fontsize=12)\n",
    "ax1.set_ylabel('Density', fontsize=12)\n",
    "ax1.set_title('Marginal Posterior for Mean', fontsize=13)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Marginal posterior for sigma^2\n",
    "sigma2_values = np.linspace(0.5, 12, 1000)\n",
    "posterior_sigma2 = stats.invgamma.pdf(sigma2_values, alpha_n, scale=beta_n)\n",
    "\n",
    "ax2.fill_between(sigma2_values, 0, posterior_sigma2, alpha=0.3, color='red')\n",
    "ax2.fill_between(sigma2_values[(sigma2_values >= ci_sigma2_lower) & (sigma2_values <= ci_sigma2_upper)],\n",
    "                  0,\n",
    "                  posterior_sigma2[(sigma2_values >= ci_sigma2_lower) & (sigma2_values <= ci_sigma2_upper)],\n",
    "                  alpha=0.5, color='darkred',\n",
    "                  label=f'95% CI: [{ci_sigma2_lower:.2f}, {ci_sigma2_upper:.2f}]')\n",
    "ax2.plot(sigma2_values, posterior_sigma2, 'r-', linewidth=2)\n",
    "ax2.axvline(beta_n/(alpha_n-1), color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Post. mean = {beta_n/(alpha_n-1):.2f}')\n",
    "ax2.axvline(true_sigma2, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'True σ² = {true_sigma2}')\n",
    "ax2.set_xlabel('σ²', fontsize=12)\n",
    "ax2.set_ylabel('Density', fontsize=12)\n",
    "ax2.set_title('Marginal Posterior for Variance', fontsize=13)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bayesian_normal_both.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian Inference for Normal (both parameters unknown)\n",
    "======================================================================\n",
    "True parameters: μ = 10, σ² = 4\n",
    "Data: n = 20, x̄ = 9.66\n",
    "\n",
    "Prior: Normal-Gamma(8, 1, 2, 2)\n",
    "\n",
    "Posterior: Normal-Gamma(9.58, 21, 12.0, 38.33)\n",
    "\n",
    "Posterior mean of μ: 9.58\n",
    "Posterior mean of σ²: 3.48\n",
    "\n",
    "Marginal posterior for μ: t_{24}(9.58, 0.39²)\n",
    "95% Credible Interval for μ: [8.77, 10.38]\n",
    "\n",
    "Marginal posterior for σ²: Inverse-Gamma(12.0, 38.33)\n",
    "95% Credible Interval for σ²: [1.95, 6.18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_bf2c79a0c64c.png)\n",
    "\n",
    "\n",
    "## Posterior Predictive Distribution\n",
    "\n",
    "### Definition\n",
    "\n",
    "Predict a **new observation** \\(\\tilde{x}\\) given observed data:\n",
    "\n",
    "$$\n",
    "p(\\tilde{x} \\mid x_1, \\ldots, x_n) = \\int p(\\tilde{x} \\mid \\mu, \\sigma^2) p(\\mu, \\sigma^2 \\mid x_1, \\ldots, x_n) d\\mu d\\sigma^2\n",
    "$$\n",
    "\n",
    "### Result for Normal-Gamma\n",
    "\n",
    "The posterior predictive is a **Student's t-distribution**:\n",
    "\n",
    "$$\n",
    "\\tilde{x} \\mid x_1, \\ldots, x_n \\sim t_{2\\alpha_n}\\left(\\mu_n, \\frac{\\beta_n(\\kappa_n+1)}{\\alpha_n\\kappa_n}\\right)\n",
    "$$\n",
    "\n",
    "### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using posteriors from previous example\n",
    "\n",
    "# Posterior predictive distribution\n",
    "df_pred = 2 * alpha_n\n",
    "scale_pred = np.sqrt(beta_n * (kappa_n + 1) / (alpha_n * kappa_n))\n",
    "\n",
    "print(\"\\nPosterior Predictive Distribution\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Distribution: t_{{{df_pred:.0f}}}({mu_n:.2f}, {scale_pred:.2f}²)\")\n",
    "\n",
    "# 95% prediction interval\n",
    "pred_lower = stats.t.ppf(0.025, df_pred, loc=mu_n, scale=scale_pred)\n",
    "pred_upper = stats.t.ppf(0.975, df_pred, loc=mu_n, scale=scale_pred)\n",
    "\n",
    "print(f\"95% Prediction Interval: [{pred_lower:.2f}, {pred_upper:.2f}]\")\n",
    "print(f\"\\nThis interval will contain the next observation with 95% probability\")\n",
    "\n",
    "# Compare with credible interval for mu\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  95% CI for μ:          [{ci_mu_lower:.2f}, {ci_mu_upper:.2f}]  (width: {ci_mu_upper-ci_mu_lower:.2f})\")\n",
    "print(f\"  95% Prediction interval: [{pred_lower:.2f}, {pred_upper:.2f}]  (width: {pred_upper-pred_lower:.2f})\")\n",
    "print(f\"\\nPrediction interval is wider (accounts for data variability + parameter uncertainty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Posterior Predictive Distribution\n",
    "======================================================================\n",
    "Distribution: t_{24}(9.58, 1.83²)\n",
    "95% Prediction Interval: [5.80, 13.35]\n",
    "\n",
    "This interval will contain the next observation with 95% probability\n",
    "\n",
    "Comparison:\n",
    "  95% CI for μ:          [8.77, 10.38]  (width: 1.61)\n",
    "  95% Prediction interval: [5.80, 13.35]  (width: 7.55)\n",
    "\n",
    "Prediction interval is wider (accounts for data variability + parameter uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Bayesian Inference for Normal Distribution\n",
    "\n",
    "| Unknown | Known | Prior | Posterior |\n",
    "|---------|-------|-------|------------|\n",
    "| \\(\\mu\\) | \\(\\sigma^2\\) | Normal | Normal |\n",
    "| \\(\\sigma^2\\) | \\(\\mu\\) | Inverse-Gamma | Inverse-Gamma |\n",
    "| Both | None | Normal-Gamma | Normal-Gamma |\n",
    "\n",
    "### Key Points\n",
    "\n",
    "1. **Normal-Normal conjugacy**: Clean, interpretable updates when \\(\\sigma^2\\) known\n",
    "2. **Precision formulation**: Makes calculations cleaner (precisions add)\n",
    "3. **Normal-Gamma**: Handles realistic case of both parameters unknown\n",
    "4. **Marginal posteriors**: Can get distributions for each parameter separately\n",
    "5. **Predictive distribution**: Always wider than parameter credible intervals\n",
    "\n",
    "### Why Student's t Appears\n",
    "\n",
    "When marginalizing over an uncertain variance, the Normal distribution becomes a **t-distribution**:\n",
    "- Heavier tails (more uncertainty)\n",
    "- Degrees of freedom increase with more data\n",
    "- Approaches Normal as \\(n \\to \\infty\\)\n",
    "\n",
    "This is why we use t-tests in frequentist statistics!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}