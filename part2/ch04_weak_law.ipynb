{
 "cells": [
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "# 4.3 The Weak Law of Large Numbers\n",
    "\n",
    "The **Weak Law of Large Numbers** is one of the most important results in probability and statistics. It tells us that if we repeat an experiment many times, the average of the results will be close to the expected value with high probability.\n",
    "\n",
    "This justifies:\n",
    "- **Simulation**: Running many trials approximates theoretical behavior\n",
    "- **Sampling**: Large samples reveal population properties\n",
    "- **Monte Carlo methods**: Random sampling for numerical computation\n",
    "- **Statistical inference**: Estimating parameters from data\n",
    "\n",
    "## 4.3.1 IID Samples\n",
    "\n",
    "### Definition: IID\n",
    "\n",
    "Random variables $X_1, X_2, \\ldots, X_N$ are **independent and identically distributed** (IID) if:\n",
    "1. They are mutually independent\n",
    "2. They all have the same probability distribution\n",
    "\n",
    "### Sample Mean\n",
    "\n",
    "The **sample mean** of $N$ IID random variables is:\n",
    "$$\\bar{X}_N = \\frac{1}{N}\\sum_{i=1}^{N} X_i$$\n",
    "\n",
    "This is itself a random variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate many sample means\n",
    "np.random.seed(42)\n",
    "num_experiments = 10000\n",
    "\n",
    "# For different sample sizes\n",
    "sample_sizes = [1, 5, 20, 100]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    sample_means = []\n",
    "    for _ in range(num_experiments):\n",
    "        # Roll n dice and compute mean\n",
    "        rolls = np.random.randint(1, 7, size=n)\n",
    "        sample_means.append(np.mean(rolls))\n",
    "    \n",
    "    axes[idx].hist(sample_means, bins=50, edgecolor='black', density=True, alpha=0.7)\n",
    "    axes[idx].axvline(3.5, color='r', linestyle='--', linewidth=2, label='E[X] = 3.5')\n",
    "    axes[idx].set_xlabel('Sample Mean')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].set_title(f'Distribution of Sample Mean (n={n})')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"n={n}: Mean of sample means = {np.mean(sample_means):.4f}, Std = {np.std(sample_means):.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1: Mean of sample means = 3.4999, Std = 1.7086\n",
    "n=5: Mean of sample means = 3.5086, Std = 0.7675\n",
    "n=20: Mean of sample means = 3.4987, Std = 0.3814\n",
    "n=100: Mean of sample means = 3.4994, Std = 0.1714"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_7faa2cc94263.png)\n",
    "\n",
    "\n",
    "**Observation**: As $N$ increases, the distribution of $\\bar{X}_N$ becomes:\n",
    "1. More concentrated around $E[X]$\n",
    "2. Narrower (smaller variance)\n",
    "3. More symmetric\n",
    "\n",
    "## 4.3.2 Two Inequalities\n",
    "\n",
    "Before proving the weak law, we need two important inequalities that bound probabilities using expectations.\n",
    "\n",
    "### Markov's Inequality\n",
    "\n",
    "For any **non-negative** random variable $X$ and $a > 0$:\n",
    "$$P(X \\geq a) \\leq \\frac{E[X]}{a}$$\n",
    "\n",
    "**Intuition**: If the expected value is small, the probability of seeing a large value must be small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Markov's Inequality\n",
    "from scipy import stats\n",
    "\n",
    "# Exponential distribution with mean 2\n",
    "lambda_rate = 0.5\n",
    "expected_value = 1 / lambda_rate\n",
    "\n",
    "# Check inequality for different values of a\n",
    "a_values = [2, 4, 6, 8, 10]\n",
    "\n",
    "print(\"Markov's Inequality: P(X ≥ a) ≤ E[X]/a\")\n",
    "print(f\"For X ~ Exponential(λ={lambda_rate}), E[X] = {expected_value}\\n\")\n",
    "\n",
    "for a in a_values:\n",
    "    true_prob = 1 - stats.expon.cdf(a, scale=1/lambda_rate)\n",
    "    markov_bound = expected_value / a\n",
    "    print(f\"a = {a:2d}: P(X ≥ {a}) = {true_prob:.4f} ≤ {markov_bound:.4f} ✓\")\n",
    "\n",
    "# Visualize\n",
    "x = np.linspace(0, 15, 1000)\n",
    "pdf = stats.expon.pdf(x, scale=1/lambda_rate)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, pdf, 'b-', linewidth=2, label='PDF')\n",
    "for a in [4, 8]:\n",
    "    plt.fill_between(x, 0, pdf, where=(x>=a), alpha=0.3, label=f'P(X ≥ {a})')\n",
    "    plt.axvline(a, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.title(\"Markov's Inequality Visualization\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markov's Inequality: P(X ≥ a) ≤ E[X]/a\n",
    "For X ~ Exponential(λ=0.5), E[X] = 2.0\n",
    "\n",
    "a =  2: P(X ≥ 2) = 0.3679 ≤ 1.0000 ✓\n",
    "a =  4: P(X ≥ 4) = 0.1353 ≤ 0.5000 ✓\n",
    "a =  6: P(X ≥ 6) = 0.0498 ≤ 0.3333 ✓\n",
    "a =  8: P(X ≥ 8) = 0.0183 ≤ 0.2500 ✓\n",
    "a = 10: P(X ≥ 10) = 0.0067 ≤ 0.2000 ✓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_9cebe6b1d6e7.png)\n",
    "\n",
    "\n",
    "### Chebyshev's Inequality\n",
    "\n",
    "For any random variable $X$ with mean $\\mu$ and variance $\\sigma^2$, and any $k > 0$:\n",
    "$$P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}$$\n",
    "\n",
    "Equivalently:\n",
    "$$P(|X - E[X]| \\geq \\epsilon) \\leq \\frac{\\text{Var}(X)}{\\epsilon^2}$$\n",
    "\n",
    "**Intuition**: The probability of being far from the mean is bounded by the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Chebyshev's Inequality\n",
    "from scipy import stats\n",
    "\n",
    "# Normal distribution\n",
    "mu, sigma = 100, 15\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(\"\\nChebyshev's Inequality: P(|X - μ| ≥ kσ) ≤ 1/k²\")\n",
    "print(f\"For X ~ Normal(μ={mu}, σ={sigma})\\n\")\n",
    "\n",
    "for k in k_values:\n",
    "    true_prob = 1 - (stats.norm.cdf(mu + k*sigma, mu, sigma) - \n",
    "                      stats.norm.cdf(mu - k*sigma, mu, sigma))\n",
    "    chebyshev_bound = 1 / k**2\n",
    "    print(f\"k = {k}: P(|X - {mu}| ≥ {k}×{sigma}) = {true_prob:.4f} ≤ {chebyshev_bound:.4f} ✓\")\n",
    "\n",
    "# Visualize\n",
    "x = np.linspace(mu - 5*sigma, mu + 5*sigma, 1000)\n",
    "pdf = stats.norm.pdf(x, mu, sigma)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, pdf, 'b-', linewidth=2, label='PDF')\n",
    "\n",
    "for k in [1, 2, 3]:\n",
    "    plt.fill_between(x, 0, pdf, \n",
    "                     where=((x <= mu - k*sigma) | (x >= mu + k*sigma)), \n",
    "                     alpha=0.2, label=f'P(|X - μ| ≥ {k}σ)')\n",
    "    plt.axvline(mu - k*sigma, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(mu + k*sigma, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.axvline(mu, color='black', linestyle='-', linewidth=2, label='μ')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.title(\"Chebyshev's Inequality Visualization\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chebyshev's Inequality: P(|X - μ| ≥ kσ) ≤ 1/k²\n",
    "For X ~ Normal(μ=100, σ=15)\n",
    "\n",
    "k = 1: P(|X - 100| ≥ 1×15) = 0.3173 ≤ 1.0000 ✓\n",
    "k = 2: P(|X - 100| ≥ 2×15) = 0.0455 ≤ 0.2500 ✓\n",
    "k = 3: P(|X - 100| ≥ 3×15) = 0.0027 ≤ 0.1111 ✓\n",
    "k = 4: P(|X - 100| ≥ 4×15) = 0.0001 ≤ 0.0625 ✓\n",
    "k = 5: P(|X - 100| ≥ 5×15) = 0.0000 ≤ 0.0400 ✓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_466690de6910.png)\n",
    "\n",
    "\n",
    "## 4.3.3 Proving the Inequalities\n",
    "\n",
    "### Proof of Markov's Inequality\n",
    "\n",
    "For non-negative $X$ and $a > 0$:\n",
    "\n",
    "$$E[X] = \\int_0^\\infty x \\cdot p(x) \\, dx$$\n",
    "$$\\geq \\int_a^\\infty x \\cdot p(x) \\, dx$$\n",
    "$$\\geq \\int_a^\\infty a \\cdot p(x) \\, dx$$\n",
    "$$= a \\cdot P(X \\geq a)$$\n",
    "\n",
    "Therefore: $P(X \\geq a) \\leq \\frac{E[X]}{a}$\n",
    "\n",
    "### Proof of Chebyshev's Inequality\n",
    "\n",
    "Let $Y = (X - \\mu)^2$. This is non-negative, so we can apply Markov's inequality:\n",
    "\n",
    "$$P(Y \\geq \\epsilon^2) \\leq \\frac{E[Y]}{\\epsilon^2}$$\n",
    "\n",
    "Now:\n",
    "- $E[Y] = E[(X - \\mu)^2] = \\text{Var}(X)$\n",
    "- $P(Y \\geq \\epsilon^2) = P((X - \\mu)^2 \\geq \\epsilon^2) = P(|X - \\mu| \\geq \\epsilon)$\n",
    "\n",
    "Therefore:\n",
    "$$P(|X - \\mu| \\geq \\epsilon) \\leq \\frac{\\text{Var}(X)}{\\epsilon^2}$$\n",
    "\n",
    "## 4.3.4 The Weak Law of Large Numbers\n",
    "\n",
    "### Theorem: Weak Law of Large Numbers\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_N$ be IID random variables with mean $\\mu$ and finite variance $\\sigma^2$. Let:\n",
    "$$\\bar{X}_N = \\frac{1}{N}\\sum_{i=1}^{N} X_i$$\n",
    "\n",
    "Then for any $\\epsilon > 0$:\n",
    "$$\\lim_{N \\to \\infty} P(|\\bar{X}_N - \\mu| \\geq \\epsilon) = 0$$\n",
    "\n",
    "Equivalently:\n",
    "$$\\lim_{N \\to \\infty} P(|\\bar{X}_N - \\mu| < \\epsilon) = 1$$\n",
    "\n",
    "**In words**: As $N$ increases, the sample mean gets arbitrarily close to the expected value with probability approaching 1.\n",
    "\n",
    "### Proof\n",
    "\n",
    "By linearity of expectation:\n",
    "$$E[\\bar{X}_N] = E\\left[\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right] = \\frac{1}{N}\\sum_{i=1}^{N} E[X_i] = \\frac{1}{N} \\cdot N\\mu = \\mu$$\n",
    "\n",
    "Since $X_i$ are independent:\n",
    "$$\\text{Var}(\\bar{X}_N) = \\text{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} X_i\\right) = \\frac{1}{N^2}\\sum_{i=1}^{N} \\text{Var}(X_i) = \\frac{\\sigma^2}{N}$$\n",
    "\n",
    "Applying Chebyshev's inequality:\n",
    "$$P(|\\bar{X}_N - \\mu| \\geq \\epsilon) \\leq \\frac{\\text{Var}(\\bar{X}_N)}{\\epsilon^2} = \\frac{\\sigma^2}{N\\epsilon^2}$$\n",
    "\n",
    "As $N \\to \\infty$, the right side goes to 0. ∎\n",
    "\n",
    "### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the Weak Law\n",
    "np.random.seed(42)\n",
    "\n",
    "# True mean of a die\n",
    "true_mean = 3.5\n",
    "\n",
    "# Compute running average\n",
    "max_n = 10000\n",
    "rolls = np.random.randint(1, 7, size=max_n)\n",
    "running_mean = np.cumsum(rolls) / np.arange(1, max_n + 1)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Full range\n",
    "ax1.plot(running_mean, 'b-', linewidth=1, alpha=0.7, label='Sample Mean')\n",
    "ax1.axhline(true_mean, color='r', linestyle='--', linewidth=2, label=f'E[X] = {true_mean}')\n",
    "ax1.fill_between(range(max_n), true_mean - 0.1, true_mean + 0.1, alpha=0.2, color='green', label='±0.1')\n",
    "ax1.set_xlabel('Number of Rolls (N)')\n",
    "ax1.set_ylabel('Sample Mean')\n",
    "ax1.set_title('Weak Law of Large Numbers: Die Rolls')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim([0, max_n])\n",
    "\n",
    "# Zoomed in on tail\n",
    "ax2.plot(range(5000, max_n), running_mean[5000:], 'b-', linewidth=1, alpha=0.7)\n",
    "ax2.axhline(true_mean, color='r', linestyle='--', linewidth=2, label=f'E[X] = {true_mean}')\n",
    "ax2.fill_between(range(5000, max_n), true_mean - 0.05, true_mean + 0.05, \n",
    "                  alpha=0.2, color='green', label='±0.05')\n",
    "ax2.set_xlabel('Number of Rolls (N)')\n",
    "ax2.set_ylabel('Sample Mean')\n",
    "ax2.set_title('Convergence (N ≥ 5000)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim([5000, max_n])\n",
    "ax2.set_ylim([3.3, 3.7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAfter {max_n} rolls:\")\n",
    "print(f\"Sample mean: {running_mean[-1]:.6f}\")\n",
    "print(f\"True mean: {true_mean}\")\n",
    "print(f\"Error: {abs(running_mean[-1] - true_mean):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After 10000 rolls:\n",
    "Sample mean: 3.499900\n",
    "True mean: 3.5\n",
    "Error: 0.000100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "![Plot](images/output_a0438f6c5991.png)\n",
    "\n",
    "\n",
    "### Convergence Rate\n",
    "\n",
    "Chebyshev's inequality tells us:\n",
    "$$P(|\\bar{X}_N - \\mu| \\geq \\epsilon) \\leq \\frac{\\sigma^2}{N\\epsilon^2}$$\n",
    "\n",
    "To guarantee $P(|\\bar{X}_N - \\mu| < \\epsilon) \\geq 1 - \\delta$, we need:\n",
    "$$N \\geq \\frac{\\sigma^2}{\\epsilon^2 \\delta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples needed?\n",
    "sigma_squared = 35/12  # Variance of a die roll\n",
    "epsilon = 0.1  # Desired accuracy\n",
    "delta = 0.05  # Acceptable failure probability\n",
    "\n",
    "N_required = sigma_squared / (epsilon**2 * delta)\n",
    "\n",
    "print(f\"\\nTo guarantee |X̄_N - μ| < {epsilon} with probability ≥ {1-delta}:\")\n",
    "print(f\"Need N ≥ {N_required:.0f} samples\")\n",
    "\n",
    "# Verify\n",
    "np.random.seed(42)\n",
    "num_trials = 10000\n",
    "successes = 0\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    sample = np.random.randint(1, 7, size=int(N_required))\n",
    "    sample_mean = np.mean(sample)\n",
    "    if abs(sample_mean - 3.5) < epsilon:\n",
    "        successes += 1\n",
    "\n",
    "empirical_prob = successes / num_trials\n",
    "print(f\"\\nEmpirical verification ({num_trials} trials):\")\n",
    "print(f\"Success rate: {empirical_prob:.4f}\")\n",
    "print(f\"Guaranteed rate: {1-delta:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To guarantee |X̄_N - μ| < 0.1 with probability ≥ 0.95:\n",
    "Need N ≥ 5833 samples\n",
    "\n",
    "Empirical verification (10000 trials):\n",
    "Success rate: 1.0000\n",
    "Guaranteed rate: 0.9500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": null,
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "```{admonition} Key Results\n",
    ":class: important\n",
    "\n",
    "**Markov's Inequality**: For non-negative $X$:\n",
    "$$P(X \\geq a) \\leq \\frac{E[X]}{a}$$\n",
    "\n",
    "**Chebyshev's Inequality**:\n",
    "$$P(|X - \\mu| \\geq \\epsilon) \\leq \\frac{\\sigma^2}{\\epsilon^2}$$\n",
    "\n",
    "**Weak Law of Large Numbers**: For IID $X_1, \\ldots, X_N$ with mean $\\mu$:\n",
    "$$\\lim_{N \\to \\infty} P(|\\bar{X}_N - \\mu| < \\epsilon) = 1$$\n",
    "\n",
    "**Practical implication**: Sample means converge to expected values!\n",
    "```\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "1. **Justifies simulation**: Compute $E[X]$ by averaging many samples\n",
    "2. **Enables estimation**: Use sample statistics to estimate population parameters\n",
    "3. **Validates randomized algorithms**: Average performance approaches expected performance\n",
    "4. **Supports Monte Carlo methods**: Random sampling for numerical integration and optimization\n",
    "5. **Founds statistical inference**: Basis for confidence intervals and hypothesis tests\n",
    "\n",
    "## Practice Problems\n",
    "\n",
    "1. Use Markov's inequality to bound $P(X \\geq 10)$ if $E[X] = 2$.\n",
    "\n",
    "2. Use Chebyshev's inequality to bound $P(|X - 50| \\geq 10)$ if $\\text{Var}(X) = 25$.\n",
    "\n",
    "3. How many coin flips do you need so that the sample proportion of heads is within 0.01 of 0.5 with probability at least 0.99?\n",
    "\n",
    "4. Simulate 10,000 experiments where you roll a die 100 times. What fraction have sample mean within 0.2 of 3.5?\n",
    "\n",
    "## Next Section\n",
    "\n",
    "Now let's see how to use expectations and the weak law in practical decision-making.\n",
    "\n",
    "→ Continue to [4.4 Using the Weak Law of Large Numbers](ch04_applications.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}